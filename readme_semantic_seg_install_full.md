
# ğŸ§  Semantic Segmentation Installation Guide for Jetson Nano

Here is a detailed, step-by-step setup guide to run the segmav semantic navigation project on a Jetson Nano Developer Kit â€” written clearly and thoroughly for practical use.

---

## âœ… OVERVIEW
This project uses:
â€¢ Jetson Nano with JetPack SDK  
â€¢ Camera (like Raspberry Pi V2)  
â€¢ Flight controller (like Pixhawk) using MAVLink  
â€¢ Jetson Inference tools with a pretrained segmentation model

---

## ğŸ“ FOLDER STRUCTURE (after setup)
```
~/segmav/
â”œâ”€â”€ mavsegmav.py         â† main robot control code
â”œâ”€â”€ segmav.py            â† segmentation + steering logic
â”œâ”€â”€ segmav.service       â† systemd auto-start file (optional)
â”œâ”€â”€ README.md
â”œâ”€â”€ screenshot.png
â””â”€â”€ jetson-inference/    â† cloned Jetson inference library with models
```

---

## ğŸ§  PREREQUISITES

### âš™ï¸ 1. Flash JetPack on Jetson Nano
Use NVIDIA SDK Manager or download JetPack SD image:  
ğŸ”— [JetPack for Jetson Nano (SD Card)](https://developer.nvidia.com/embedded/jetpack)

â€¢ Flash to SD card using Balena Etcher  
â€¢ Boot Nano with monitor, keyboard, or via SSH  
â€¢ Connect to Wi-Fi or Ethernet

---

## ğŸ§° 2. Install system packages

Open terminal on Nano:
```bash
sudo apt update
sudo apt install -y git cmake libpython3-dev python3-pip python3-numpy                     python3-opencv python3-pil libjpeg-dev libfreetype6-dev                     libcanberra-gtk-module python3-pyserial                     libopenblas-dev libopenmpi-dev gfortran                     libjpeg-dev zlib1g-dev libjpeg8-dev libpng-dev                     libavcodec-dev libavformat-dev libswscale-dev
```

---

## ğŸ“¦ INSTALL jetson-inference (FROM SOURCE)

### ğŸ” 3. Clone and build
```bash
cd ~
git clone --recursive https://github.com/dusty-nv/jetson-inference
cd jetson-inference

# Configure build and models
mkdir build
cd build
cmake ../
```

### âœ… Choose "Pretrained models" â†’ segmentation â†’ `fcn-resnet18-cityscapes-1024x512`

Use arrow keys to move.  
Press SPACEBAR to check:
```
[*] segmentation--fcn-resnet18-cityscapes-1024x512
```
Then press:
â€¢ Enter to accept  
â€¢ `c` to configure  
â€¢ `g` to generate  
â€¢ Exit the menu

---

### ğŸ› ï¸ 2. Build and Install
```bash
make -j4         # Compiles everything
sudo make install
sudo ldconfig    # Update shared library cache
```

---

## âœ… Confirm install
```bash
cd ~/jetson-inference/build/aarch64/bin
./segnet-console.py --help
```

---

## ğŸ¤– INSTALL segmav PROJECT

### ğŸ“¥ 4. Clone your segmav code
```bash
cd ~
git clone https://github.com/YOUR-REPO/segmav.git
cd segmav
```

Or unzip the one you already have and rename:
```bash
unzip segmav-main\ \(1\).zip
mv segmav-main segmav
```

---

## ğŸ§© 5. Install Python dependencies
```bash
cd ~/segmav
pip3 install numpy opencv-python pymavlink jetson-inference
```

---

## ğŸ¥ 6. Plug in Camera and Pixhawk

â€¢ Use the Raspberry Pi V2 camera or USB webcam  
â€¢ Connect Jetson UART (or USB) to Pixhawk via MAVLink  
â€¢ Make sure MAVLink is routed to `udp:14552`  
Use mavproxy or mavlink-router if needed.

---

## â–¶ï¸ 7. Run it!
```bash
cd ~/segmav
python3 mavsegmav.py
```
If it works, you should see:
â€¢ The camera stream  
â€¢ MAVLink messages about yaw and speed being sent  
â€¢ The robot start steering based on sidewalk segmentation

---

## ğŸ”„ OPTIONAL: Run on Boot

To auto-start at boot, enable the systemd service:
```bash
sudo cp segmav.service /etc/systemd/system/
sudo systemctl daemon-reexec
sudo systemctl enable segmav.service
sudo systemctl start segmav.service
```

Make sure the service ExecStart path matches your install location.

---

## ğŸ§ª TROUBLESHOOTING

| Problem           | Solution                                                   |
|-------------------|------------------------------------------------------------|
| Jetson overheating| Add a fan                                                  |
| No camera detected| Try `ls /dev/video*`, use cheese or opencv to test         |
| MAVLink timeout   | Ensure correct port and connection on flight controller    |
| SegNet error      | Make sure jetson-inference was installed from source, not apt |

---

## âœ… STEP-BY-STEP: Install fcn-resnet18-cityscapes-1024x512

During the CMake setup of jetson-inference, a GUI menu lets you choose which pre-trained models to download. Hereâ€™s what to do:

---

### ğŸ” 1. CMake Menu (Model Downloader)

```bash
cd ~/jetson-inference/build
cmake ../
```

âœ… This will open a menu that looks like this:

```
BUILD_PYTHON       ON
INSTALL_PREFIX     /usr/local
...

[ ] segmentation--fcn-resnet18-cityscapes-1024x512
```

ğŸ‘‰ USE THE ARROW KEYS to move.  
âœ… Press SPACEBAR on:

```
[*] segmentation--fcn-resnet18-cityscapes-1024x512
```

ğŸ’¾ Then press:  
â€¢ Enter to accept  
â€¢ `c` to configure  
â€¢ `g` to generate  
â€¢ Then exit

---

### ğŸ› ï¸ 2. Build and Install
```bash
make -j4         # Compiles everything
sudo make install
sudo ldconfig    # Update shared library cache
```

---

## ğŸ“ FINAL FOLDER STRUCTURE (Jetson)

Hereâ€™s what your Jetson Nano home directory should look like when done:
```
~/                 â† Your Jetson Nano home
â”œâ”€â”€ jetson-inference/
â”‚   â”œâ”€â”€ build/
â”‚   â”‚   â”œâ”€â”€ aarch64/bin/
â”‚   â”‚   â”‚   â””â”€â”€ segnet.py  â† segmentation executable
â”‚   â”‚   â”œâ”€â”€ CMakeFiles/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ networks/
â”‚   â”‚       â””â”€â”€ fcn-resnet18-cityscapes-1024x512/
â”‚   â”‚           â”œâ”€â”€ labels.txt
â”‚   â”‚           â”œâ”€â”€ fcn_resnet18.onnx
â”‚   â”‚           â””â”€â”€ other model files
â”‚   â””â”€â”€ python/
â”‚       â””â”€â”€ jetson_inference/
â”‚       â””â”€â”€ jetson_utils/
â”‚
â”œâ”€â”€ segmav/
â”‚   â”œâ”€â”€ mavsegmav.py
â”‚   â”œâ”€â”€ segmav.py
â”‚   â”œâ”€â”€ segmav.service
â”‚   â”œâ”€â”€ screenshot.png
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ catkin_ws/           â† Youâ€™ll create this later for ROS
    â”œâ”€â”€ src/
    â””â”€â”€ build/
```

---

## ğŸ’¡ How to Test the Model

You can test the installed model with a sample image or live camera:

```bash
cd ~/jetson-inference/build/aarch64/bin
./segnet.py --network=fcn-resnet18-cityscapes-1024x512 /dev/video0
```

If your camera works, you should see real-time segmentation with purple sidewalks.

---

## ğŸ› ï¸ READY TO ADD ROS?

Youâ€™re now ready to add a ROS Catkin workspace in `~/catkin_ws/` without affecting the `segmav` or `jetson-inference` setups.
